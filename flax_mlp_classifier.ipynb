{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxYmSoJyW_x",
        "outputId": "a31c7819-98fc-47ad-b19a-ce68c969ef0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.7/129.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m231.3/231.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m344.1/344.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
        "!pip install -q flax optax transformers datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£ Import Required Libraries"
      ],
      "metadata": {
        "id": "dBUo9DUQysbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import optax  # Optimizers\n"
      ],
      "metadata": {
        "id": "MLx74tJzywui"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2ï¸âƒ£ Define a Simple Neural Network using Flax"
      ],
      "metadata": {
        "id": "xAy97wyAy1i1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    hidden_dim: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Dense(self.hidden_dim)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(1)(x)  # Output layer\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uviln5Jyy4te"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3ï¸âƒ£ Initialize Model Parameters"
      ],
      "metadata": {
        "id": "xGg4woV9y7xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(hidden_dim=32)\n",
        "key = jax.random.PRNGKey(0)\n",
        "x_dummy = jnp.ones((1, 10))  # Example input\n",
        "params = model.init(key, x_dummy)  # Initialize model\n",
        "print(params)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elRQxEDgy_vd",
        "outputId": "84f57863-1b09-4611-9d70-696b5dc8b20a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'params': {'Dense_0': {'kernel': Array([[-0.5223456 ,  0.23860869, -0.43568492, -0.26943007,  0.29074085,\n",
            "         0.40591595,  0.3301583 , -0.01470341,  0.1336994 ,  0.24582365,\n",
            "        -0.57535076,  0.2701447 , -0.2233426 ,  0.16106607,  0.38631102,\n",
            "        -0.08694729, -0.4690676 , -0.41746357, -0.22493699, -0.01054574,\n",
            "        -0.10714039, -0.19746391, -0.6667231 , -0.17042542, -0.36339986,\n",
            "        -0.19222786,  0.17231458, -0.23188609,  0.40331432,  0.38735247,\n",
            "         0.5382161 , -0.46305057],\n",
            "       [ 0.19625618,  0.5367912 ,  0.27752233, -0.07770313, -0.00775636,\n",
            "        -0.2685969 ,  0.35266262,  0.15011781,  0.18526915, -0.08636144,\n",
            "        -0.03711447,  0.21603984,  0.15343831,  0.00115734,  0.12622738,\n",
            "        -0.33444613,  0.12262806, -0.44731817, -0.2748209 ,  0.2535692 ,\n",
            "         0.33146128,  0.30883512,  0.6163292 , -0.01071304, -0.13781956,\n",
            "         0.33463055,  0.15033457, -0.12188746, -0.39209256,  0.2970293 ,\n",
            "        -0.16921943, -0.20661804],\n",
            "       [ 0.48238912,  0.38126814,  0.48083243,  0.59948206,  0.04144247,\n",
            "        -0.41725564, -0.57579786, -0.14976366,  0.354732  ,  0.02222719,\n",
            "        -0.12487796, -0.17056786, -0.52867377, -0.01697146, -0.47818515,\n",
            "         0.13627946,  0.13590954,  0.07111628, -0.01871487, -0.38474768,\n",
            "        -0.2504447 , -0.1768748 ,  0.30006316, -0.55995333,  0.4818766 ,\n",
            "        -0.00701312, -0.41904593,  0.09802416,  0.23518352,  0.3771968 ,\n",
            "         0.00638405,  0.366018  ],\n",
            "       [ 0.12599851,  0.21912071, -0.03254937, -0.23205295, -0.35381648,\n",
            "        -0.20401257,  0.27334443, -0.0910966 , -0.00166049,  0.13543142,\n",
            "         0.0677867 ,  0.07743373, -0.6136596 , -0.08772971,  0.14468737,\n",
            "        -0.3466326 , -0.69703096, -0.12786217,  0.04150098,  0.5620674 ,\n",
            "        -0.58474576, -0.24009754,  0.09814803, -0.14239223, -0.5134919 ,\n",
            "        -0.3512463 ,  0.17017315, -0.22372392, -0.26830563,  0.07786624,\n",
            "        -0.02812692, -0.11472059],\n",
            "       [-0.52559674, -0.27399865,  0.24290882, -0.1761235 ,  0.16496803,\n",
            "         0.12757038,  0.22281535,  0.28685215,  0.4154137 , -0.5159518 ,\n",
            "        -0.39822853, -0.41469505, -0.6154333 ,  0.3470821 ,  0.60715497,\n",
            "         0.18416795, -0.01357802, -0.45954886, -0.30375856,  0.5574078 ,\n",
            "        -0.6408385 ,  0.19585833, -0.4125529 ,  0.08837592, -0.28784052,\n",
            "         0.0073775 ,  0.18081406,  0.47886845, -0.11468355,  0.2154868 ,\n",
            "         0.18323016, -0.5588036 ],\n",
            "       [-0.2715983 ,  0.6338341 , -0.06301526,  0.287424  ,  0.17430003,\n",
            "        -0.32839683, -0.03226502, -0.6753764 , -0.07054746, -0.43438587,\n",
            "        -0.30080995,  0.26654416, -0.12597963, -0.30108583,  0.4693608 ,\n",
            "        -0.07324079,  0.0306768 ,  0.15746422,  0.5414243 , -0.2305399 ,\n",
            "         0.19011341, -0.11604523, -0.1288853 , -0.22027217,  0.3087877 ,\n",
            "        -0.2822311 , -0.15977052, -0.2001469 , -0.1088796 , -0.17711759,\n",
            "         0.2643716 , -0.41883326],\n",
            "       [-0.00914139,  0.667592  , -0.2449979 ,  0.42905942,  0.32580423,\n",
            "         0.07019818, -0.03595516,  0.4069065 , -0.20589012, -0.10317972,\n",
            "         0.22183315, -0.26796535, -0.3529392 , -0.02497619, -0.42631033,\n",
            "        -0.24452405, -0.27057362,  0.5615502 ,  0.4317163 ,  0.3857559 ,\n",
            "        -0.45525232,  0.02699917, -0.15100187, -0.05116415,  0.4372763 ,\n",
            "         0.03861921,  0.11718075,  0.1049368 , -0.05788514, -0.0683625 ,\n",
            "        -0.42651108, -0.40108132],\n",
            "       [-0.11100701, -0.3569776 , -0.34236348,  0.20484523,  0.6051771 ,\n",
            "         0.26645467, -0.07015854,  0.3179099 , -0.35206154,  0.121607  ,\n",
            "         0.5544234 , -0.32144237,  0.05615347,  0.716881  , -0.44801804,\n",
            "        -0.08630253,  0.30209914, -0.15545921,  0.2188271 , -0.30537134,\n",
            "        -0.01596913, -0.08953433,  0.21686149, -0.06362561,  0.17339726,\n",
            "        -0.44176975, -0.32795852,  0.05381972,  0.60977846, -0.24933799,\n",
            "         0.06234792, -0.39379707],\n",
            "       [ 0.15493618,  0.14781278,  0.6268085 , -0.12027555, -0.62538785,\n",
            "        -0.04290274, -0.28210592, -0.26335338,  0.32244745, -0.54535437,\n",
            "        -0.49846593,  0.37540314, -0.2934098 ,  0.5370786 , -0.47764242,\n",
            "        -0.11659528, -0.2787645 ,  0.03956339, -0.10028332, -0.700661  ,\n",
            "         0.1197549 ,  0.26581812, -0.36139375,  0.24980107, -0.10424611,\n",
            "         0.31104773, -0.49750385, -0.44708842,  0.12255403,  0.15788382,\n",
            "         0.29956692, -0.00368778],\n",
            "       [-0.11753882,  0.34221324,  0.6869396 , -0.01126156, -0.41834933,\n",
            "        -0.18294919,  0.30464128,  0.1274994 ,  0.29958323,  0.05535897,\n",
            "        -0.40303987, -0.01536319,  0.36864573,  0.04394327, -0.5203229 ,\n",
            "         0.34930676, -0.3941526 , -0.5126767 ,  0.4431552 ,  0.25126615,\n",
            "        -0.4043258 , -0.33827767, -0.5871591 , -0.47076565, -0.11937887,\n",
            "        -0.31129894, -0.43569216,  0.22719486, -0.01855696, -0.16730134,\n",
            "         0.09298074,  0.0052557 ]], dtype=float32), 'bias': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float32)}, 'Dense_1': {'kernel': Array([[ 0.00058821],\n",
            "       [ 0.05661301],\n",
            "       [ 0.03196427],\n",
            "       [-0.14859381],\n",
            "       [ 0.11380663],\n",
            "       [ 0.15446164],\n",
            "       [-0.19728579],\n",
            "       [-0.1273901 ],\n",
            "       [ 0.13182606],\n",
            "       [ 0.08481817],\n",
            "       [ 0.07803881],\n",
            "       [ 0.11666732],\n",
            "       [-0.05186866],\n",
            "       [-0.0797805 ],\n",
            "       [ 0.08982614],\n",
            "       [ 0.17344975],\n",
            "       [ 0.10006365],\n",
            "       [ 0.07056616],\n",
            "       [-0.02670955],\n",
            "       [-0.31755126],\n",
            "       [-0.00253629],\n",
            "       [-0.02249789],\n",
            "       [ 0.32921103],\n",
            "       [-0.1256663 ],\n",
            "       [-0.1167165 ],\n",
            "       [ 0.21651715],\n",
            "       [ 0.20096105],\n",
            "       [ 0.06551589],\n",
            "       [-0.08429192],\n",
            "       [-0.22261174],\n",
            "       [ 0.10545055],\n",
            "       [-0.08419642]], dtype=float32), 'bias': Array([0.], dtype=float32)}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is flax.linen.Module?\n",
        "In Flax, flax.linen.Module is the base class for defining neural networks.\n",
        "It follows an object-oriented approach, where each model is a Python class that defines:\n",
        "Layers (e.g., Dense, Conv)\n",
        "Activation functions (e.g., ReLU, Sigmoid)\n",
        "The forward pass (__call__ method)\n",
        "\n",
        "\n",
        "ğŸ”¹ Explanation of Components in flax.linen.Module\n",
        "Component- Explanation\n",
        "hidden_dim: int-\tDefines the number of hidden neurons (passed as an argument when creating the model).\n",
        "@nn.compact\t-A decorator that allows layers to be defined inside __call__ instead of setup().\n",
        "__call__(self, x)-\tThe forward function where data flows through layers.\n",
        "nn.Dense(self.hidden_dim)(x)-\tA fully connected layer with hidden_dim neurons.\n",
        "nn.relu(x)\tActivation function (ReLU introduces non-linearity).\n",
        "nn.Dense(1)(x)-\tFinal output layer with 1 neuron (useful for regression tasks).\n",
        "model.init(key, x_dummy)-\tInitializes weights using a random key.\n",
        "\n"
      ],
      "metadata": {
        "id": "hZ-WpQZJ0W7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ Alternative Way: Using setup() Instead of @nn.compact\n",
        "Flax models can also be defined using setup(), where layers are declared as instance attributes."
      ],
      "metadata": {
        "id": "Vq8TufMb1g4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    hidden_dim: int\n",
        "\n",
        "    def setup(self):\n",
        "        self.dense1 = nn.Dense(self.hidden_dim)\n",
        "        self.dense2 = nn.Dense(1)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.dense1(x)\n",
        "        x = nn.relu(x)\n",
        "        x = self.dense2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "b2P9lHy91iaF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Difference?\n",
        "\n",
        "setup() stores layers as attributes (self.dense1), making them reusable in different parts of the model.\n",
        "@nn.compact is simpler and more concise but does not allow layer reuse.\n",
        "\n"
      ],
      "metadata": {
        "id": "8bKnMkok1mir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NG51Cmpg1sDe"
      }
    }
  ]
}